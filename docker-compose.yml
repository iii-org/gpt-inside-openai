version: '3.7'
networks:
    nginx_network:
        external:
            name: nginx_network

services:
    gpt-insight-model-openai:
        container_name: gpt-insight-model-openai
        build:
            context: ./build/train
            dockerfile: dockerfile
        image: iii-dsi/gpt-insight-model:openai
        stdin_open: true
        tty: true
        volumes:
            - ./src/train:/app
            - ./data:/data
        environment:
            TZ: "Asia/Taipei"
            OPENAI_API_TYPE: ${OPENAI_API_TYPE}
            OPENAI_API_BASE: ${OPENAI_API_BASE}
            OPENAI_API_VERSION: ${OPENAI_API_VERSION}
            OPENAI_API_KEY: ${OPENAI_API_KEY}
        logging:
            driver: "json-file"
            options:
                max-size: "1g"
        ulimits:
            memlock: -1
        networks:
            - nginx_network

    gpt-insight-inference-openai:
        container_name: gpt-insight-inference-openai
        restart: always
        build:
            context: ./build/inference
            dockerfile: dockerfile
        image: iii-dsi/gpt-insight-inference:openai
        volumes:
            - ./src/inference:/app
            - ./data:/data
            - ./build/inference/nginx:/etc/nginx/conf.d
            - ./log:/chat_log
        environment:
            TZ: "Asia/Taipei"
            REF_DATA: "/data/mic_qa.xlsx"
            OPENAI_API_TYPE: ${OPENAI_API_TYPE}
            OPENAI_API_BASE: ${OPENAI_API_BASE}
            OPENAI_API_VERSION: ${OPENAI_API_VERSION}
            OPENAI_API_KEY: ${OPENAI_API_KEY}
            OPENAI_ENGINE: ${OPENAI_ENGINE}
            OPENAI_ENCODER: ${OPENAI_ENCODER}
            UWSGI_CHEAPER: "0"
            UWSGI_PROCESSES: "1"
        logging:
            driver: "json-file"
            options:
                max-size: "1g"
        ulimits:
            memlock: -1
        ports:
            - 52023:80
        networks:
            - nginx_network

    gpt-insight-web-openai:
        image: nginx:1.19.3
        container_name: gpt-insight-web-openai
        restart: always
        environment:
            TZ: "Asia/Taipei"
        volumes:
            - ./build/interface/nginx.conf:/etc/nginx/nginx.conf
            - ./build/interface/config/:/etc/nginx/conf.d/
            - ./build/interface/web:/web
        ports:
            - 80:80
            - 443:443
        logging:
            driver: "json-file"
            options:
                max-size: "1g"
        networks:
            - nginx_network
